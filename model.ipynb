{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import joblib\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "\n",
    "\n",
    "# 讀取上傳的文件\n",
    "'''\n",
    "north_data = pd.read_csv('D:/DS_Prediction/Weather/north_weekly_averages.csv')\n",
    "south_data = pd.read_csv('D:/DS_Prediction/Weather/south_weekly_averages.csv')\n",
    "central_data = pd.read_csv('D:/DS_Prediction/Weather/central_weekly_averages.csv')\n",
    "east_data = pd.read_csv('D:/DS_Prediction/Weather/east_weekly_averages.csv')\n",
    "fuel_prices = pd.read_csv('D:/DS_Prediction/fuel_prices.csv')\n",
    "cabbage_prices = pd.read_csv('D:/DS_Prediction/Domestic_Cabbage.csv')\n",
    "'''\n",
    "\n",
    "north_data = pd.read_csv('./weather-csv/north_weekly_averages.csv')\n",
    "south_data = pd.read_csv('./weather-csv/south_weekly_averages.csv')\n",
    "central_data = pd.read_csv('./weather-csv/central_weekly_averages.csv')\n",
    "east_data = pd.read_csv('./weather-csv/east_weekly_averages.csv')\n",
    "fuel_prices = pd.read_csv('./fuel_prices.csv')\n",
    "cabbage_prices = pd.read_csv('./vegetable-csv/Domestic_Cabbage.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data saved to All_X.csv\n",
      "                       date_x    平均價       交易量  year  month  week  平均氣壓(hPa)  \\\n",
      "0   2019-01-01 00:00:00+00:00  22.22   4487.67  2019      1     0    1019.18   \n",
      "1   2019-01-01 00:00:00+00:00  22.22   4487.67  2019      1     0    1019.90   \n",
      "2   2019-01-01 00:00:00+00:00  22.22   4487.67  2019      1     0    1020.22   \n",
      "3   2019-01-01 00:00:00+00:00  22.22   4487.67  2019      1     0    1017.62   \n",
      "4   2019-01-08 00:00:00+00:00  20.40   4323.00  2019      1     1    1016.19   \n",
      "..                        ...    ...       ...   ...    ...   ...        ...   \n",
      "922 2024-11-12 00:00:00+00:00  47.13  14259.17  2024     11     1    1006.90   \n",
      "923 2024-11-25 00:00:00+00:00  40.70  17676.00  2024     11     3    1015.60   \n",
      "924 2024-11-25 00:00:00+00:00  40.70  17676.00  2024     11     3    1014.70   \n",
      "925 2024-11-25 00:00:00+00:00  40.70  17676.00  2024     11     3    1016.55   \n",
      "926 2024-11-25 00:00:00+00:00  40.70  17676.00  2024     11     3    1013.20   \n",
      "\n",
      "     平均氣溫(℃)  平均相對溼度( %)  平均風速(m/s)  累計雨量(mm)  累積日射量(MJ/m2)  \\\n",
      "0      17.33       95.67       3.53      2.50          6.57   \n",
      "1      19.53       89.83       1.40      4.00          6.81   \n",
      "2      19.42       83.00       4.40      0.00         11.32   \n",
      "3      20.00       82.33       1.70      0.08         11.20   \n",
      "4      18.63       93.14       2.61      0.00          7.28   \n",
      "..       ...         ...        ...       ...           ...   \n",
      "922    24.80       91.86       1.27      8.50         10.08   \n",
      "923    18.40       83.00       4.20      1.00          5.10   \n",
      "924    21.15       81.50       1.75      5.75         11.34   \n",
      "925    21.65       76.50       3.65      0.00         15.82   \n",
      "926    22.25       84.00       2.25      0.00         16.58   \n",
      "\n",
      "                       date_y    Fuel_92    Fuel_95  Fuel_High  \n",
      "0                         NaT  27.883333  29.383333  25.983333  \n",
      "1                         NaT  27.883333  29.383333  25.983333  \n",
      "2                         NaT  27.883333  29.383333  25.983333  \n",
      "3                         NaT  27.883333  29.383333  25.983333  \n",
      "4   2019-01-07 00:00:00+00:00  25.000000  26.500000  22.700000  \n",
      "..                        ...        ...        ...        ...  \n",
      "922 2024-11-11 00:00:00+00:00  28.400000  29.900000  26.800000  \n",
      "923 2024-11-25 00:00:00+00:00  28.600000  30.100000  27.200000  \n",
      "924 2024-11-25 00:00:00+00:00  28.600000  30.100000  27.200000  \n",
      "925 2024-11-25 00:00:00+00:00  28.600000  30.100000  27.200000  \n",
      "926 2024-11-25 00:00:00+00:00  28.600000  30.100000  27.200000  \n",
      "\n",
      "[927 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "'''\n",
    "Data Processing\n",
    "\n",
    "'''\n",
    "##\n",
    "\n",
    "# Merge regional data into a single DataFrame\n",
    "regional_data_1 = pd.concat([north_data, south_data, central_data, east_data], ignore_index=True)\n",
    "\n",
    "\n",
    "# Check and rename date columns if necessary\n",
    "def ensure_date_column(df, possible_names):\n",
    "    for col in df.columns:\n",
    "        if col in possible_names:\n",
    "            df.rename(columns={col: 'date'}, inplace=True)\n",
    "            break\n",
    "    return df\n",
    "\n",
    "# Rename the date columns where applicable\n",
    "regional_data = ensure_date_column(regional_data_1, ['週', 'date'])\n",
    "fuel_prices = ensure_date_column(fuel_prices, ['Date', 'date', '週', '日期'])\n",
    "cabbage_prices = ensure_date_column(cabbage_prices, ['週', 'date'])\n",
    "\n",
    "# Convert date columns to datetime\n",
    "def parse_date(df, column_name):\n",
    "    if column_name in df.columns:\n",
    "        df[column_name] = pd.to_datetime(df[column_name], errors='coerce', utc=True)\n",
    "    return df\n",
    "\n",
    "regional_data = parse_date(regional_data, 'date')\n",
    "fuel_prices = parse_date(fuel_prices, 'date')\n",
    "cabbage_prices = parse_date(cabbage_prices, 'date')\n",
    "\n",
    "# Drop rows with missing or invalid 'date' values\n",
    "for df in [regional_data, fuel_prices, cabbage_prices]:\n",
    "    if 'date' in df.columns:\n",
    "        df.dropna(subset=['date'], inplace=True)\n",
    "\n",
    "# Ensure 'date' columns are consistent and datetimelike\n",
    "for df in [regional_data, fuel_prices, cabbage_prices]:\n",
    "    if 'date' in df.columns:\n",
    "        df['date'] = pd.to_datetime(df['date']).dt.normalize()\n",
    "\n",
    "# Extract additional features from date\n",
    "def extract_date_features(df, date_column):\n",
    "    df['year'] = df[date_column].dt.year\n",
    "    df['month'] = df[date_column].dt.month\n",
    "    df['week'] = df[date_column].dt.day // 7\n",
    "    return df\n",
    "\n",
    "cabbage_prices = extract_date_features(cabbage_prices, 'date')\n",
    "fuel_prices = extract_date_features(fuel_prices, 'date')\n",
    "\n",
    "# Merge all the data into a single DataFrame\n",
    "try:\n",
    "    merged_data = pd.merge(cabbage_prices, regional_data, on='date', how='left')\n",
    "    merged_data = pd.merge(merged_data, fuel_prices, on=['year', 'month', 'week'], how='left')\n",
    "except KeyError as e:\n",
    "    raise KeyError(f\"Error during merging: {e}. Please check that all dataframes contain a 'date' column.\")\n",
    "\n",
    "# 根據 Group 分組計算均值並填補缺失值\n",
    "merged_data['Fuel_92'] = merged_data.groupby('month')['Fuel_92'].transform(lambda x: x.fillna(x.mean()))\n",
    "merged_data['Fuel_95'] = merged_data.groupby('month')['Fuel_95'].transform(lambda x: x.fillna(x.mean()))\n",
    "merged_data['Fuel_High'] = merged_data.groupby('month')['Fuel_High'].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "# Handle missing values\n",
    "merged_data.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Prepare features and target variable\n",
    "y = merged_data[['平均價', '交易量']]\n",
    "X = merged_data.drop(columns=['date_x', '平均價', '交易量', 'year', 'month', 'week', 'date_y'])\n",
    "\n",
    "# Save the merged DataFrame to a CSV file\n",
    "output_file = \"All_X.csv\"\n",
    "X.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"Merged data saved to {output_file}\")\n",
    "\n",
    "print(merged_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 300, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "'''\n",
<<<<<<< HEAD
    "Build and Train the Model\n",
    "\n",
    "'''\n",
    "##\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Set up the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Set up the XGBoost model\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', verbose=0, n_jobs=-1)\n",
    "\n",
    "# Fit the model using GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best estimator and parameters\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "print(f'Best Parameters: {best_params}')"
=======
    "Building the Model\n",
    "\n",
    "'''\n",
    "##"
>>>>>>> b222f29 (Add PCA)
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "'''\n",
    "Training the Model\n",
    "\n",
    "'''\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "'''\n",
    "Evaluation\n",
    "1. 哪種蔬果準確度最高，哪種最低，並分析原因\n",
    "\n",
    "'''\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
>>>>>>> b222f29 (Add PCA)
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 1460.921431488017\n",
      "Mean Absolute Error: 1012.614337570026\n",
      "R2 Score: -27.880993208402018\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "'''\n",
    "Prediction and Evaluation\n",
    "1. 哪種蔬果準確度最高，哪種最低，並分析原因\n",
    "\n",
    "'''\n",
    "##\n",
    "# Make predictions\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'Root Mean Squared Error: {rmse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'R2 Score: {r2}')\n",
    "\n",
    "# # Save the best model\n",
    "# joblib.dump(best_model, 'cabbage_price_xgboost_best_model.pkl')\n",
    "\n",
    "# # Load and test the model\n",
    "# loaded_model = joblib.load('cabbage_price_xgboost_best_model.pkl')\n",
    "# loaded_y_pred = loaded_model.predict(X_test)\n",
    "# loaded_rmse = mean_squared_error(y_test, loaded_y_pred, squared=False)\n",
    "# print(f'Loaded Model Root Mean Squared Error: {loaded_rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
<<<<<<< HEAD
=======
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# 加载数据\n",
    "train_data = pd.read_csv('./train.csv')\n",
    "test_data = pd.read_csv('./test.csv')\n",
    "\n",
    "# 特征和目标列名\n",
    "X_columns = [\n",
    "    'north_平均氣壓(hPa)', 'north_平均氣溫(℃)', 'north_平均相對溼度( %)', 'north_平均風速(m/s)',\n",
    "    'north_累計雨量(mm)', 'north_累積日射量(MJ/m2)', 'south_平均氣壓(hPa)', 'south_平均氣溫(℃)',\n",
    "    'south_平均相對溼度( %)', 'south_平均風速(m/s)', 'south_累計雨量(mm)', 'south_累積日射量(MJ/m2)',\n",
    "    'central_平均氣壓(hPa)', 'central_平均氣溫(℃)', 'central_平均相對溼度( %)', 'central_平均風速(m/s)',\n",
    "    'central_累計雨量(mm)', 'central_累積日射量(MJ/m2)', 'east_平均氣壓(hPa)', 'east_平均氣溫(℃)',\n",
    "    'east_平均相對溼度( %)', 'east_平均風速(m/s)', 'east_累計雨量(mm)', 'east_累積日射量(MJ/m2)',\n",
    "    'Fuel_92', 'Fuel_95', 'Fuel_High', 'cabbage_平均價'\n",
    "]\n",
    "y_column = 'cabbage_交易量'\n",
    "\n",
    "# 分离特征和目标\n",
    "X_train = train_data[X_columns]\n",
    "y_train = train_data[y_column]\n",
    "X_test = test_data[X_columns]\n",
    "y_test = test_data[y_column]\n",
    "\n",
    "# 填充缺失值\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_test = imputer.transform(X_test)\n",
    "\n",
    "# 标准化\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
>>>>>>> b222f29 (Add PCA)
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Best parameters found:  {'C': 100, 'epsilon': 0.1, 'gamma': 0.001}\n",
      "Best score:  254.8068308556072\n"
=======
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "Best Parameters: {'C': 300, 'gamma': 0.05, 'kernel': 'rbf'}\n",
      "Root Mean Squared Error (RMSE): 2637.002807604907\n",
      "Mean Absolute Error (MAE): 1948.2446118641092\n",
      "R2 Score: 0.11892993034079025\n"
>>>>>>> b222f29 (Add PCA)
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "##\n",
    "'''\n",
    "Build and Train the Model\n",
    "\n",
    "'''\n",
    "y = y['平均價']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "svr_model = SVR(kernel='rbf')\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [0.001, 0.01, 0.1, 1],\n",
    "    'epsilon': [0.1, 0.2, 0.5]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=svr_model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
=======
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100, 150, 200, 250, 300],\n",
    "    'gamma': [0.001,0.005, 0.01,0.05, 0.1, 1],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "# 使用 GridSearchCV 优化单目标 SVR 模型\n",
    "svr_model = SVR()\n",
    "grid_search = GridSearchCV(estimator=svr_model, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs=-1, verbose=1)\n",
>>>>>>> b222f29 (Add PCA)
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best score: \", -grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 267.03483295942107\n",
      "Mean Absolute Error (MAE): 12.661678486923725\n",
      "R-squared (R2): 0.20833946980525286\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "'''\n",
    "Prediction and Evaluation\n",
    "1. 哪種蔬果準確度最高，哪種最低，並分析原因\n",
    "\n",
<<<<<<< HEAD
    "'''\n",
    "best_svr = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_svr.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"R-squared (R2): {r2}\")"
=======
    "# 输出最佳参数和模型\n",
    "best_model = grid_search.best_estimator_\n",
    "print(f'Best Parameters: {grid_search.best_params_}')\n",
    "\n",
    "# 使用最佳模型进行预测\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# 评估指标\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# 打印评估结果\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
    "print(f'Mean Absolute Error (MAE): {mae}')\n",
    "print(f'R2 Score: {r2}')"
>>>>>>> b222f29 (Add PCA)
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN+Transfermor"
   ]
  },
  {
<<<<<<< HEAD
=======
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "# 加载数据\n",
    "train_data = pd.read_csv('./train.csv')\n",
    "test_data = pd.read_csv('./test.csv')\n",
    "\n",
    "# 特征和目标列名\n",
    "X_columns = [\n",
    "    'north_平均氣壓(hPa)', 'north_平均氣溫(℃)', 'north_平均相對溼度( %)', 'north_平均風速(m/s)',\n",
    "    'north_累計雨量(mm)', 'north_累積日射量(MJ/m2)', 'south_平均氣壓(hPa)', 'south_平均氣溫(℃)',\n",
    "    'south_平均相對溼度( %)', 'south_平均風速(m/s)', 'south_累計雨量(mm)', 'south_累積日射量(MJ/m2)',\n",
    "    'central_平均氣壓(hPa)', 'central_平均氣溫(℃)', 'central_平均相對溼度( %)', 'central_平均風速(m/s)',\n",
    "    'central_累計雨量(mm)', 'central_累積日射量(MJ/m2)', 'east_平均氣壓(hPa)', 'east_平均氣溫(℃)',\n",
    "    'east_平均相對溼度( %)', 'east_平均風速(m/s)', 'east_累計雨量(mm)', 'east_累積日射量(MJ/m2)',\n",
    "    'Fuel_92', 'Fuel_95', 'Fuel_High'\n",
    "]\n",
    "y_column = 'cabbage_平均價'\n",
    "\n",
    "# 分离特征和目标\n",
    "X_train = train_data[X_columns]\n",
    "y_train = train_data[y_column]\n",
    "X_test = test_data[X_columns]\n",
    "y_test = test_data[y_column]\n",
    "\n",
    "# 处理缺失值\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_test = imputer.transform(X_test)\n",
    "\n",
    "# 标准化\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 重塑输入形状以适应 CNN\n",
    "X_train = X_train.reshape(-1, X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(-1, X_test.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 27, 1)]           0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 25, 64)            256       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 12, 64)            0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 10, 128)           24704     \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPoolin  (None, 5, 128)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 640)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                41024     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66049 (258.00 KB)\n",
      "Trainable params: 66049 (258.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "6/6 [==============================] - 1s 41ms/step - loss: 1197.4003 - val_loss: 1424.5928\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 913.9826 - val_loss: 959.6527\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 512.7548 - val_loss: 500.9770\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 367.9259 - val_loss: 479.6643\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 370.1605 - val_loss: 458.4691\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 309.1542 - val_loss: 509.7350\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 314.4189 - val_loss: 494.9569\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 293.2015 - val_loss: 446.7022\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 287.8135 - val_loss: 424.9255\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 284.7656 - val_loss: 430.4543\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 267.1859 - val_loss: 452.4989\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 271.2409 - val_loss: 442.3581\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 265.3698 - val_loss: 416.7938\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 258.6884 - val_loss: 413.0869\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 255.8959 - val_loss: 405.0124\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 250.6981 - val_loss: 408.7586\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 247.2220 - val_loss: 402.7580\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 243.3791 - val_loss: 399.9297\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 242.4600 - val_loss: 394.5115\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 236.1343 - val_loss: 400.7610\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 234.2902 - val_loss: 382.7673\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 242.5019 - val_loss: 369.6550\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 238.5142 - val_loss: 424.9608\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 236.3330 - val_loss: 363.7013\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 219.8351 - val_loss: 359.6099\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 217.1477 - val_loss: 362.6008\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 211.9045 - val_loss: 374.0881\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 212.8124 - val_loss: 368.0630\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 209.1088 - val_loss: 368.2909\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 206.4310 - val_loss: 354.3311\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 202.8738 - val_loss: 348.7747\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 200.6266 - val_loss: 347.7834\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 199.0978 - val_loss: 344.7249\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 195.1367 - val_loss: 331.9744\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 191.7978 - val_loss: 346.0766\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 195.6570 - val_loss: 345.3857\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 187.5883 - val_loss: 321.2481\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 189.8303 - val_loss: 315.3425\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 187.8532 - val_loss: 320.9075\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 182.8895 - val_loss: 312.1990\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 176.9620 - val_loss: 312.5382\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 177.0978 - val_loss: 305.8298\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 172.0043 - val_loss: 310.7788\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 170.5846 - val_loss: 306.2376\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 167.4522 - val_loss: 296.2782\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 164.8313 - val_loss: 293.8291\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 163.1460 - val_loss: 289.8055\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 159.8064 - val_loss: 286.9552\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 162.5232 - val_loss: 289.3187\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 155.1626 - val_loss: 275.1461\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Root Mean Squared Error: 16.587529261439425\n",
      "Mean Absolute Error: 13.754889279320128\n",
      "R2 Score: 0.20666923999786868\n"
     ]
    }
   ],
   "source": [
    "# 定义 CNN 模型\n",
    "def build_simplified_model(input_shape):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # CNN 层\n",
    "    x = layers.Conv1D(64, 3, activation='relu')(inputs)\n",
    "    x = layers.MaxPooling1D(2)(x)\n",
    "    x = layers.Conv1D(128, 3, activation='relu')(x)\n",
    "    x = layers.MaxPooling1D(2)(x)\n",
    "\n",
    "    # Flatten 层\n",
    "    x = layers.Flatten()(x)\n",
    "\n",
    "    # 全连接层\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    outputs = layers.Dense(1)(x)  # 输出预测值\n",
    "\n",
    "    # 创建模型\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# 创建模型并编译\n",
    "model = build_simplified_model((X_train.shape[1], 1))\n",
    "optimizer = optimizers.Adam(learning_rate=1e-3)\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "# 打印模型概述\n",
    "model.summary()\n",
    "\n",
    "# 训练模型\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# 预测\n",
    "y_pred = model.predict(X_test).flatten()\n",
    "\n",
    "# 评估模型\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Root Mean Squared Error: {rmse}\")\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"R2 Score: {r2}\")\n"
   ]
  },
  {
>>>>>>> b222f29 (Add PCA)
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models, optimizers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# 加载数据\n",
    "train_data = pd.read_csv('./train.csv')\n",
    "test_data = pd.read_csv('./test.csv')\n",
    "\n",
    "# 特征和目标列名\n",
    "X_columns = [\n",
    "    'north_平均氣壓(hPa)', 'north_平均氣溫(℃)', 'north_平均相對溼度( %)', 'north_平均風速(m/s)',\n",
    "    'north_累計雨量(mm)', 'north_累積日射量(MJ/m2)', 'south_平均氣壓(hPa)', 'south_平均氣溫(℃)',\n",
    "    'south_平均相對溼度( %)', 'south_平均風速(m/s)', 'south_累計雨量(mm)', 'south_累積日射量(MJ/m2)',\n",
    "    'central_平均氣壓(hPa)', 'central_平均氣溫(℃)', 'central_平均相對溼度( %)', 'central_平均風速(m/s)',\n",
    "    'central_累計雨量(mm)', 'central_累積日射量(MJ/m2)', 'east_平均氣壓(hPa)', 'east_平均氣溫(℃)',\n",
    "    'east_平均相對溼度( %)', 'east_平均風速(m/s)', 'east_累計雨量(mm)', 'east_累積日射量(MJ/m2)',\n",
    "    'Fuel_92', 'Fuel_95', 'Fuel_High', 'cabbage_交易量'  # 加入交易量作为特征\n",
    "]\n",
    "y_column = 'cabbage_平均價'\n",
    "\n",
    "# 分离特征和目标\n",
    "X_train = train_data[X_columns]\n",
    "y_train = train_data[y_column]\n",
    "X_test = test_data[X_columns]\n",
    "y_test = test_data[y_column]\n",
    "\n",
    "# 处理缺失值\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_test = imputer.transform(X_test)\n",
    "\n",
    "# 标准化\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 重塑输入形状以适应 LSTM\n",
    "X_train = X_train.reshape(-1, X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(-1, X_test.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 28, 1)]           0         \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, 28, 64)            16896     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 28, 64)            0         \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 28, 128)           98816     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 28, 128)           0         \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 256)               394240    \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 551169 (2.10 MB)\n",
      "Trainable params: 551169 (2.10 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 5s 233ms/step - loss: 1283.9504 - val_loss: 1699.7972\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 1s 90ms/step - loss: 1282.3629 - val_loss: 1697.7007\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 1s 89ms/step - loss: 1280.3386 - val_loss: 1694.8463\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 1s 88ms/step - loss: 1277.4991 - val_loss: 1690.4332\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 1s 86ms/step - loss: 1272.7289 - val_loss: 1682.6306\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 1s 88ms/step - loss: 1263.0857 - val_loss: 1666.3119\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 1s 90ms/step - loss: 1242.9805 - val_loss: 1623.8646\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 1s 100ms/step - loss: 1182.0109 - val_loss: 1486.2610\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 993.9506 - val_loss: 1128.5918\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 1s 92ms/step - loss: 684.1208 - val_loss: 863.2531\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 1s 88ms/step - loss: 516.1694 - val_loss: 713.4868\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 1s 85ms/step - loss: 408.7823 - val_loss: 590.4720\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 1s 89ms/step - loss: 317.5076 - val_loss: 492.3760\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 1s 87ms/step - loss: 264.1495 - val_loss: 424.5863\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 239.3752 - val_loss: 383.9027\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 1s 86ms/step - loss: 220.6089 - val_loss: 362.9362\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 1s 85ms/step - loss: 227.9289 - val_loss: 357.3747\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 82ms/step - loss: 221.4972 - val_loss: 356.9447\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 1s 86ms/step - loss: 229.2168 - val_loss: 358.4730\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 1s 88ms/step - loss: 224.9851 - val_loss: 360.9093\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 1s 85ms/step - loss: 220.6555 - val_loss: 365.4486\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 1s 92ms/step - loss: 223.4339 - val_loss: 367.8874\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 1s 86ms/step - loss: 225.7037 - val_loss: 367.5180\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 83ms/step - loss: 222.8874 - val_loss: 368.0564\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 1s 87ms/step - loss: 225.9443 - val_loss: 368.6916\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 1s 86ms/step - loss: 220.0904 - val_loss: 368.3957\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 221.6297 - val_loss: 368.6057\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 1s 92ms/step - loss: 218.8292 - val_loss: 368.1402\n",
      "2/2 [==============================] - 1s 0s/step\n",
      "Root Mean Squared Error: 18.892981832125468\n",
      "Mean Absolute Error: 14.100520866030736\n",
      "R2 Score: -0.02918134014286977\n"
     ]
    }
   ],
   "source": [
    "def build_lstm_model(input_shape):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # 第一层 LSTM 层\n",
    "    x = layers.LSTM(64, return_sequences=True)(inputs)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "\n",
    "    # 第二层 LSTM 层\n",
    "    x = layers.LSTM(128, return_sequences=True)(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "\n",
    "    # 第三层 LSTM 层\n",
    "    x = layers.LSTM(256)(x)\n",
<<<<<<< HEAD
    "    x = layers.Dropout(0.2)(x)\n",
=======
    "    x = layers.Dropout(0.3)(x)\n",
>>>>>>> b222f29 (Add PCA)
    "\n",
    "    # 全连接层\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    outputs = layers.Dense(1)(x)  # 输出预测值\n",
    "\n",
    "    # 创建模型\n",
<<<<<<< HEAD
    "    model = models.Model(inputs=inputs, outputs=x)\n",
=======
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
>>>>>>> b222f29 (Add PCA)
    "\n",
    "    return model\n",
    "\n",
    "# 创建 LSTM 模型并编译\n",
    "model = build_lstm_model((X_train.shape[1], 1))\n",
    "\n",
    "# 使用较小的学习率\n",
    "optimizer = optimizers.Adam(learning_rate=1e-4)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "# 打印模型概述\n",
    "model.summary()\n",
    "\n",
    "# 设置早停回调\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# 训练模型\n",
    "model.fit(X_train, y_train, epochs=200, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "# 预测\n",
    "y_pred = model.predict(X_test).flatten()\n",
    "\n",
    "# 评估模型\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Root Mean Squared Error: {rmse}\")\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"R2 Score: {r2}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
